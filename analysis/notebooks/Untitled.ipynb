{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9aea3607-0670-4565-afe0-8ab163fa6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from os import path\n",
    "from zipfile import ZipFile\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "from json import load, dump\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d2fdb8b4-2816-4db8-80a5-5a3f6b1ab66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from redis import Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "da1e99e4-3934-44d9-b89c-65222918b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.base import BaseEstimator\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e0dfc72-8253-4324-839f-10c2c1f3b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e77701-bbd4-4088-bb8b-41ac5804f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder: str = '../data'\n",
    "models_folder: str = '../models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "088f404f-f52e-4429-8ccf-457e4c14ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset(archive_name: str = 'archive.zip', file_name: str = 'Titanic-Dataset.csv') -> None:\n",
    "    \"\"\"Extract the downloaded archive file into the data folder.\"\"\"\n",
    "    # Ubuntu OS\n",
    "    downloads_path: str = path.join(path.expanduser('~'), 'Downloads')\n",
    "    archive_path: str = path.join(downloads_path, archive_name)\n",
    "    try:\n",
    "        with ZipFile(archive_path, 'r') as zip_:\n",
    "            try:\n",
    "                zip_.extract(file_name, data_folder)\n",
    "                logging.info(f'The file {file_name} has been extracted to {path.join(data_folder, file_name)}.')\n",
    "            except KeyError:\n",
    "                print(f'There is no file \"{file_name}\" in the archive \"{archive_path}\".')\n",
    "                logging.error(f'There is no file \"{file_name}\" in the archive \"{archive_path}\".')\n",
    "    except FileNotFoundError:\n",
    "        print(f'There is no archive \"{archive_path}\".')\n",
    "        logging.error(f'There is no archive \"{archive_path}\".')\n",
    "    return path.join(data_folder, file_name)\n",
    "\n",
    "def load_data(file_name: str = 'Titanic-Dataset.csv') -> DataFrame:\n",
    "    \"\"\"Load the Titanic dataset into a dataframe.\"\"\"\n",
    "    file_path: str = path.join(data_folder, file_name)\n",
    "    try:\n",
    "        data: DataFrame = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f'There is no file such file \"{file_name}\" in the data folder.')\n",
    "        logging.error(f'There is no file such file \"{file_name}\" in the data folder.')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31953b6e-310b-46f3-85ce-6e8f0eb9886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-Sep-23 16:33:15 - INFO - The file Titanic-Dataset.csv has been extracted to ../data/Titanic-Dataset.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/Titanic-Dataset.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_name: str = 'archive.zip'\n",
    "file_name: str = 'Titanic-Dataset.csv'\n",
    "data_path: str = extract_dataset()\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67cec805-fa91-4ca7-a80d-3af7f761ac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_name: str = 'Titanic-Dataset.csv'\n",
    "data: DataFrame = load_data(file_name)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1087a2c-8931-4d29-a600-a93d8bd262da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMetadata(BaseModel):\n",
    "    source: str\n",
    "    cols: list[str] = Field(default_factory=list)\n",
    "    description: str\n",
    "    path: str\n",
    "    id: str\n",
    "\n",
    "    @classmethod\n",
    "    def from_metadata(cls, metadata_file: str) -> Self:\n",
    "        \"\"\"Create metadata from metadata file.\"\"\"\n",
    "        try:\n",
    "            with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "                metadata: dict = load(f)\n",
    "        except FileNotFoundError: #JSONDecodeError\n",
    "            logging.error(f'There is no file such path \"{metadata_file}\".')\n",
    "        else:\n",
    "            return cls(**metadata)\n",
    "\n",
    "    def save(self, path: str) -> str:\n",
    "        \"\"\"Save the metadata to disk.\"\"\"\n",
    "        try:\n",
    "            with open(path, 'w', encoding='utf-8') as f:\n",
    "                dump(self.model_dump(), f)\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f'There is no file such path \"{path}\".')\n",
    "            return ''\n",
    "        return path\n",
    "\n",
    "dataset_metadata: DatasetMetadata = DatasetMetadata(\n",
    "    source='https://www.kaggle.com/datasets/yasserh/titanic-dataset',\n",
    "    cols=data.columns.values.tolist(),\n",
    "    description='A dataset that shows the survivors of the titanic tragedy.',\n",
    "    path=data_path,\n",
    "    id=f'Dataset_{str(uuid4())}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bad6c54-3731-47a4-9ccd-f912056a97a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metadata.json'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_metadata.save('metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "190592ec-3b54-4b43-b6bc-9613eaf7469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetMetadata(source='https://www.kaggle.com/datasets/yasserh/titanic-dataset', cols=['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], description='A dataset that shows the survivors of the titanic tragedy.', path='../data/Titanic-Dataset.csv', id='Dataset_73ebe0e2-3224-470f-b80f-6174521544ac')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata: DatasetMetadata = DatasetMetadata.from_metadata('metadata.json')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "009fe2bd-942a-4602-b837-9cf696da0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(BaseModel):\n",
    "    metadata: DatasetMetadata\n",
    "    dataset_path: str = metadata.path\n",
    "\n",
    "    def get_dataset(self) -> DataFrame:\n",
    "        \"\"\"Load the dataset.\"\"\"\n",
    "        data: DataFrame = pd.read_csv(self.dataset_path)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98052ae7-6308-4e86-8c28-a5cb110763cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/Titanic-Dataset.csv'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset: Dataset = DataSet(metadata=metadata)\n",
    "dataset.dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03e2f75d-0b8d-4762-98a1-70f6c8a93a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data: DataFrame = dataset.get_dataset()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f7fa71b9-5fe4-4127-81ec-def0c38f0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class Metrics(BaseModel):\n",
    "    accuracy: float\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, name: str, model: BaseEstimator, save_path: str) -> None:\n",
    "        self._model = model\n",
    "        self._name: str = name\n",
    "        self._metrics: Metrics = None\n",
    "        self._train_time: str = None\n",
    "        self.__save_path: str = save_path\n",
    "        self.date: datetime = None\n",
    "        self._trained_model: Pipeline = None\n",
    "        self.redis: Redis = Redis(\n",
    "            host='localhost',\n",
    "            port=6379\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def metrics(self) -> None:\n",
    "        return self._metrics\n",
    "\n",
    "    @metrics.setter\n",
    "    def metrics(self, metrics: Metrics) -> None:\n",
    "        self._metrics = metrics\n",
    "\n",
    "    @property\n",
    "    def trained_model(self) -> None:\n",
    "        return self._trained_model\n",
    "\n",
    "    @trained_model.setter\n",
    "    def trained_model(self, trained_model: Pipeline) -> None:\n",
    "        self._trained_model = trained_model\n",
    "\n",
    "    @property\n",
    "    def name(self) -> None:\n",
    "        return self._name\n",
    "\n",
    "    @name.setter\n",
    "    def name(self, name: str) -> None:\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def model(self) -> None:\n",
    "        return self._model\n",
    "\n",
    "    @model.setter\n",
    "    def model(self, model: BaseEstimator) -> None:\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def train_time(self) -> None:\n",
    "        return self._train_time\n",
    "\n",
    "    @train_time.setter\n",
    "    def train_time(self, train_time: float) -> None:\n",
    "        self._train_time = train_time\n",
    "\n",
    "    @property\n",
    "    def date(self) -> None:\n",
    "        return self._date\n",
    "\n",
    "    @date.setter\n",
    "    def date(self, date: datetime) -> None:\n",
    "        self._date = date\n",
    "\n",
    "    def post_model_metrics(self) -> None:\n",
    "        accuracy: str = 'models:accuracy'\n",
    "        precision: str = 'models:precision'\n",
    "        train_time: str = 'models:train_time'\n",
    "        self.redis.zadd(name=accuracy, mapping={self.name: self.metrics.accuracy})\n",
    "        self.redis.zadd(name=precision, mapping={self.name: self.metrics.precision})\n",
    "        self.redis.zadd(name=train_time, mapping={self.name: self.train_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "6df8aba5-9905-4378-b971-e5bd2ee01aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentConfig(BaseModel):\n",
    "    data_dir: str\n",
    "    models_directory: str\n",
    "    features_dir: str\n",
    "    dataset_metadata: DatasetMetadata\n",
    "    label_columns: list[str] = Field(default_factory=list)\n",
    "    feature_cols: list[str] = Field(default_factory=list)\n",
    "    columns_to_drop: list[str] = Field(default_factory=list)\n",
    "\n",
    "class Experiment:\n",
    "    def __init__(self, experiment_config: ExperimentConfig, preprocessor: ColumnTransformer, models: dict[str, BaseEstimator]):\n",
    "        self.experiment_config = experiment_config\n",
    "        self.preprocessor = preprocessor\n",
    "        self.models = models\n",
    "        self.dataset: DataSet = DataSet(metadata=experiment_config.dataset_metadata)\n",
    "    \n",
    "    def get_features(self) -> DataFrame:\n",
    "        data: DataFrame = dataset.get_dataset()\n",
    "        features: DataFrame = data[experiment_config.feature_cols]\n",
    "        return features\n",
    "\n",
    "    def get_labels(self) -> Series:\n",
    "        data: DataFrame = dataset.get_dataset()\n",
    "        labels: Series = data[experiment_config.label_columns]\n",
    "        return labels\n",
    "\n",
    "    def get_train_test_data(self) -> ((DataFrame, Series), (DataFrame, Series)):\n",
    "        features = self.get_features()\n",
    "        labels = self.get_labels()\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            features, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        return (train_features, train_labels), (test_features, test_labels)\n",
    "\n",
    "    def save_features(self) -> DataFrame:\n",
    "        pas\n",
    "\n",
    "    def save_labels(self) -> DataFrame:\n",
    "        pass\n",
    "\n",
    "    def train_model(self, model: Model) -> float:\n",
    "        (train_features, train_labels), (test_features, test_labels) = self.get_train_test_data()\n",
    "        pipeline: Pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('classifier', model.model)\n",
    "        ])\n",
    "        train_start_time: float = time.perf_counter()\n",
    "        pipeline.fit(train_features, train_labels.values.ravel())\n",
    "        train_stop_time: float = time.perf_counter()\n",
    "        predictions: list[int] = pipeline.predict(test_features).tolist()\n",
    "        accuracy: float = accuracy_score(test_labels, predictions)\n",
    "        precision: float = precision_score(test_labels, predictions)\n",
    "        recall: float = recall_score(test_labels, predictions)\n",
    "        f1: float = f1_score(test_labels, predictions)\n",
    "        model.metrics = Metrics(\n",
    "            accuracy=round(accuracy,2),\n",
    "            precision=round(precision,2),\n",
    "            recall=round(recall,2),\n",
    "            f1=round(f1,2)\n",
    "        )\n",
    "        model.train_time = train_stop_time - train_start_time\n",
    "        model.data = datetime.now()\n",
    "        model.trained_model = pipeline\n",
    "        model.post_model_metrics()\n",
    "        return model\n",
    "\n",
    "    def run(self) -> None:\n",
    "        for model in self.models:\n",
    "            trained_model: Model = self.train_model(model)\n",
    "            print(model.name, model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2c0f8b27-b25c-44db-a886-1dbfd3afa4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata: DatasetMetadata = DatasetMetadata.from_metadata('metadata.json')\n",
    "experiment_config: ExperimentConfig = ExperimentConfig(\n",
    "    data_dir='../data',\n",
    "    models_directory='../models',\n",
    "    features_dir='../features',\n",
    "    dataset_metadata=metadata,\n",
    "    label_columns=['Survived'],\n",
    "    feature_cols=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', \"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"],\n",
    "    columns_to_drop=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "30785d54-b7c6-4594-a5d6-617b8fa46fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop: list[str] = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "numerical_features = [\"Age\", \"Fare\"]\n",
    "categorical_features = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('num', num_pipeline, numerical_features),\n",
    "        ('cat', cat_pipeline, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "3962421a-e67f-4a1e-a1b6-e714e30f6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "models: list[Model] = [\n",
    "    Model(\n",
    "        save_path=path.join(models_folder, model_name),\n",
    "        model=model,\n",
    "        name=model_name\n",
    "    ) \n",
    "    for model_name, model in zip(names, classifiers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b9a4cb2a-5340-47bf-acd4-fac8aaec9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment: Experiment = Experiment(\n",
    "    experiment_config=experiment_config,\n",
    "    preprocessor=preprocessor,\n",
    "    models=models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3bfab04c-187a-489a-9b9f-3bf7fb0c35e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors accuracy=0.83 precision=0.79 recall=0.75 f1=0.77\n",
      "Linear SVM accuracy=0.78 precision=0.74 recall=0.65 f1=0.69\n",
      "RBF SVM accuracy=0.78 precision=0.72 recall=0.68 f1=0.7\n",
      "Gaussian Process accuracy=0.82 precision=0.82 recall=0.67 f1=0.74\n",
      "Decision Tree accuracy=0.82 precision=0.78 recall=0.75 f1=0.76\n",
      "Random Forest accuracy=0.77 precision=0.75 recall=0.58 f1=0.66\n",
      "Neural Net accuracy=0.8 precision=0.85 recall=0.58 f1=0.69\n",
      "AdaBoost accuracy=0.79 precision=0.72 recall=0.74 f1=0.73\n",
      "Naive Bayes accuracy=0.78 precision=0.72 recall=0.7 f1=0.71\n",
      "QDA accuracy=0.64 precision=0.57 recall=0.23 f1=0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyle/tutorial/titanic_analysis/venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b7e6965c-0545-4f09-be5e-8fbbff0d722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Sep-23 17:00:37 - DEBUG - matplotlib data path: /home/lyle/tutorial/titanic_analysis/venv/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "24-Sep-23 17:00:37 - DEBUG - CONFIGDIR=/home/lyle/.config/matplotlib\n",
      "24-Sep-23 17:00:37 - DEBUG - interactive is False\n",
      "24-Sep-23 17:00:37 - DEBUG - platform is linux\n",
      "24-Sep-23 17:00:37 - DEBUG - CACHEDIR=/home/lyle/.cache/matplotlib\n",
      "24-Sep-23 17:00:37 - DEBUG - Using fontManager instance from /home/lyle/.cache/matplotlib/fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8e40299d-4811-4104-a8b6-8bd0fcc4ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = experiment.get_features()\n",
    "labels = experiment.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "581217e8-d952-4df3-8576-13f85e49d325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "40510b96-a7c5-42d4-bdfd-7de902a117a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "2cfd3bdc-49a0-422c-a9b1-7a61799ce3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_elimination(model, faetures, labels):\n",
    "    rfecv = RFECV(estimator=model, \n",
    "                  step=1, \n",
    "                  cv=StratifiedKFold(10),\n",
    "                  scoring='accuracy')\n",
    "    rfecv.fit(faetures, labels.values.ravel())\n",
    "    return rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "4129b988-3cff-4496-84ba-81cb10bf7878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when `importance_getter=='auto'`, the underlying estimator SVC should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n",
      "when `importance_getter=='auto'`, the underlying estimator GaussianProcessClassifier should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n",
      "Optimum number of features for Decision Tree is: 7\n",
      "[0, 1, 2, 4, 6, 9, 10]\n",
      "0.6871508379888268\n",
      "Optimum number of features for Random Forest is: 7\n",
      "index 7 is out of bounds for axis 0 with size 7\n",
      "when `importance_getter=='auto'`, the underlying estimator MLPClassifier should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n",
      "Optimum number of features for AdaBoost is: 7\n",
      "index 7 is out of bounds for axis 0 with size 7\n",
      "when `importance_getter=='auto'`, the underlying estimator GaussianNB should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n",
      "when `importance_getter=='auto'`, the underlying estimator QuadraticDiscriminantAnalysis should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = experiment.get_train_test_data()\n",
    "train_features = preprocessor.fit_transform(train_features)\n",
    "test_features = preprocessor.fit_transform(test_features)\n",
    "for model_data in models[2:]:\n",
    "    try:\n",
    "        model = model_data.model\n",
    "        rfecv = feature_elimination(model, train_features, train_labels)\n",
    "        print(f\"Optimum number of features for {model_data.name} is: {rfecv.n_features_}\")\n",
    "        df_features = pd.DataFrame(columns = ['feature', 'support', 'ranking'])\n",
    "\n",
    "        for i in range(features.shape[1]):\n",
    "            row = {'feature': i, 'support': rfecv.support_[i], 'ranking': rfecv.ranking_[i]}\n",
    "            df_features = pd.concat([df_features, pd.DataFrame([row])], ignore_index=True)\n",
    "            \n",
    "        df_features.sort_values(by='ranking').head(10)\n",
    "        df_features = df_features[df_features['support']==True]\n",
    "        cols = df_features.feature.values.tolist()\n",
    "        print(cols)\n",
    "        train_features = train_features[:, cols]\n",
    "        model.fit(train_features, train_labels.values.ravel())\n",
    "        predictions: list[int] = model.predict(test_features[:, cols]).tolist()\n",
    "        accuracy: float = accuracy_score(test_labels, predictions)\n",
    "        print(accuracy)\n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9adad79b-d280-445b-8376-e7d92f3ac072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimum number of features: %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "795b9fe9-b443-4981-8e09-253cafe3a614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 4, 6, 7, 9, 10, 11]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = pd.DataFrame(columns = ['feature', 'support', 'ranking'])\n",
    "\n",
    "for i in range(features.shape[1]):\n",
    "    row = {'feature': i, 'support': rfecv.support_[i], 'ranking': rfecv.ranking_[i]}\n",
    "    df_features = pd.concat([df_features, pd.DataFrame([row])], ignore_index=True)\n",
    "    \n",
    "df_features.sort_values(by='ranking').head(10)\n",
    "df_features = df_features[df_features['support']==True]\n",
    "cols = df_features.feature.values.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "386f9912-d195-4b34-81ca-daba88654d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>support</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature support ranking\n",
       "0        0    True       1\n",
       "1        1    True       1\n",
       "4        4    True       1\n",
       "5        5    True       1\n",
       "10      10    True       1\n",
       "11      11    True       1"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x = df_features[df_features['support']==True]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "fd8efbd9-02be-4ada-a7b0-82a67f87264a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 5, 10, 11]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.feature.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "a9486c10-f337-4349-aad0-8ac5caa4946f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 , -0.50244517,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.63878901,  0.78684529,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.2846632 , -0.48885426,  0.        ,  0.        ,  1.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = features[0:3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "1a09c2d5-e715-4845-927f-6bcc6f611b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 , -0.50244517,  1.        ,  0.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.63878901,  0.78684529,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ],\n",
       "       [-0.2846632 , -0.48885426,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, x.feature.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "6f0e2b41-59ee-4793-a4b5-5545444acd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str) -> Pipeline:\n",
    "    \"\"\"Load a saved model.\"\"\"\n",
    "    try:\n",
    "        model: Pipeline = joblib.load(model_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f'There is no such model \"{model_path}\".')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f7ecb88c-b238-4bf5-8366-b47242c684df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;PassengerId&#x27;, &#x27;Name&#x27;,\n",
       "                                                   &#x27;Ticket&#x27;, &#x27;Cabin&#x27;]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Age&#x27;, &#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Sex&#x27;,\n",
       "                                                   &#x27;Embarked&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, KNeighborsClassifier(n_neighbors=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;PassengerId&#x27;, &#x27;Name&#x27;,\n",
       "                                                   &#x27;Ticket&#x27;, &#x27;Cabin&#x27;]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Age&#x27;, &#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Sex&#x27;,\n",
       "                                                   &#x27;Embarked&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, KNeighborsClassifier(n_neighbors=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                 [&#x27;PassengerId&#x27;, &#x27;Name&#x27;, &#x27;Ticket&#x27;, &#x27;Cabin&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Age&#x27;, &#x27;Fare&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;, OneHotEncoder())]),\n",
       "                                 [&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop_columns</label><div class=\"sk-toggleable__content\"><pre>[&#x27;PassengerId&#x27;, &#x27;Name&#x27;, &#x27;Ticket&#x27;, &#x27;Cabin&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;Fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;SibSp&#x27;, &#x27;Parch&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('drop_columns', 'drop',\n",
       "                                                  ['PassengerId', 'Name',\n",
       "                                                   'Ticket', 'Cabin']),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Age', 'Fare']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['Pclass', 'Sex',\n",
       "                                                   'Embarked'])])),\n",
       "                ('classifier', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/home/lyle/tutorial/titanic_analysis/analysis/models/trained/Nearest Neighbors'\n",
    "model = load_model(model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ccc60e70-946e-4380-9f1c-1ec49d65f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "2e33ae58-aa62-42d6-8ac2-c95ee5e26efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(remainder='passthrough',\n",
       "                     transformers=[('drop_columns', 'drop',\n",
       "                                    ['PassengerId', 'Name', 'Ticket', 'Cabin']),\n",
       "                                   ('num',\n",
       "                                    Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                                    ('scaler', StandardScaler())]),\n",
       "                                    ['Age', 'Fare']),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                    ('encoder', OneHotEncoder())]),\n",
       "                                    ['Pclass', 'Sex', 'Embarked'])])),\n",
       "  ('classifier', KNeighborsClassifier(n_neighbors=3))],\n",
       " 'verbose': False,\n",
       " 'preprocessor': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('drop_columns', 'drop',\n",
       "                                  ['PassengerId', 'Name', 'Ticket', 'Cabin']),\n",
       "                                 ('num',\n",
       "                                  Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                                  ('scaler', StandardScaler())]),\n",
       "                                  ['Age', 'Fare']),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                  ('encoder', OneHotEncoder())]),\n",
       "                                  ['Pclass', 'Sex', 'Embarked'])]),\n",
       " 'classifier': KNeighborsClassifier(n_neighbors=3),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'passthrough',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('drop_columns',\n",
       "   'drop',\n",
       "   ['PassengerId', 'Name', 'Ticket', 'Cabin']),\n",
       "  ('num',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler())]),\n",
       "   ['Age', 'Fare']),\n",
       "  ('cat',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                   ('encoder', OneHotEncoder())]),\n",
       "   ['Pclass', 'Sex', 'Embarked'])],\n",
       " 'preprocessor__verbose': False,\n",
       " 'preprocessor__verbose_feature_names_out': True,\n",
       " 'preprocessor__drop_columns': 'drop',\n",
       " 'preprocessor__num': Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler())]),\n",
       " 'preprocessor__cat': Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                 ('encoder', OneHotEncoder())]),\n",
       " 'preprocessor__num__memory': None,\n",
       " 'preprocessor__num__steps': [('imputer', SimpleImputer()),\n",
       "  ('scaler', StandardScaler())],\n",
       " 'preprocessor__num__verbose': False,\n",
       " 'preprocessor__num__imputer': SimpleImputer(),\n",
       " 'preprocessor__num__scaler': StandardScaler(),\n",
       " 'preprocessor__num__imputer__add_indicator': False,\n",
       " 'preprocessor__num__imputer__copy': True,\n",
       " 'preprocessor__num__imputer__fill_value': None,\n",
       " 'preprocessor__num__imputer__keep_empty_features': False,\n",
       " 'preprocessor__num__imputer__missing_values': nan,\n",
       " 'preprocessor__num__imputer__strategy': 'mean',\n",
       " 'preprocessor__num__scaler__copy': True,\n",
       " 'preprocessor__num__scaler__with_mean': True,\n",
       " 'preprocessor__num__scaler__with_std': True,\n",
       " 'preprocessor__cat__memory': None,\n",
       " 'preprocessor__cat__steps': [('imputer',\n",
       "   SimpleImputer(strategy='most_frequent')),\n",
       "  ('encoder', OneHotEncoder())],\n",
       " 'preprocessor__cat__verbose': False,\n",
       " 'preprocessor__cat__imputer': SimpleImputer(strategy='most_frequent'),\n",
       " 'preprocessor__cat__encoder': OneHotEncoder(),\n",
       " 'preprocessor__cat__imputer__add_indicator': False,\n",
       " 'preprocessor__cat__imputer__copy': True,\n",
       " 'preprocessor__cat__imputer__fill_value': None,\n",
       " 'preprocessor__cat__imputer__keep_empty_features': False,\n",
       " 'preprocessor__cat__imputer__missing_values': nan,\n",
       " 'preprocessor__cat__imputer__strategy': 'most_frequent',\n",
       " 'preprocessor__cat__encoder__categories': 'auto',\n",
       " 'preprocessor__cat__encoder__drop': None,\n",
       " 'preprocessor__cat__encoder__dtype': numpy.float64,\n",
       " 'preprocessor__cat__encoder__feature_name_combiner': 'concat',\n",
       " 'preprocessor__cat__encoder__handle_unknown': 'error',\n",
       " 'preprocessor__cat__encoder__max_categories': None,\n",
       " 'preprocessor__cat__encoder__min_frequency': None,\n",
       " 'preprocessor__cat__encoder__sparse': 'deprecated',\n",
       " 'preprocessor__cat__encoder__sparse_output': True,\n",
       " 'classifier__algorithm': 'auto',\n",
       " 'classifier__leaf_size': 30,\n",
       " 'classifier__metric': 'minkowski',\n",
       " 'classifier__metric_params': None,\n",
       " 'classifier__n_jobs': None,\n",
       " 'classifier__n_neighbors': 3,\n",
       " 'classifier__p': 2,\n",
       " 'classifier__weights': 'uniform'}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "4a40aeb8-4143-4777-a7cd-8a804aa932e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = experiment.get_train_test_data()\n",
    "train_features = preprocessor.fit_transform(train_features)\n",
    "test_features = preprocessor.fit_transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "62860261-f165-4598-af82-63610ede0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)#Fit the model\n",
    "best_model = clf.fit(train_features, train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "62eb5132-b0cd-407c-9b01-b9b209d08721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 1,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 25,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "2282c343-3881-43fb-a974-ea14a6645c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 12), (179, 12))"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "059015dc-67ab-4b57-93f2-d2e393ccf46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6871508379888268"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = best_model.predict(test_features)\n",
    "accuray = accuracy_score(preds, test_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba568cd9-e8d2-4111-88c7-b8ae840012cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
